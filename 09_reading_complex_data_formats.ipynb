{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "378b0791-5969-4b4e-a779-110ebd9fac6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "        SparkSession\n",
    "        .builder\n",
    "        .appName(\"Reading Complex Data Formats\")\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c49b857-0814-40d1-8d07-6f2b0c0ad06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=501407609248767#setting/sparkui/0622-151559-nni5vbfv/driver-4375923195119470111\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=501407609248767#setting/sparkui/0622-151559-nni5vbfv/driver-4375923195119470111\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130c0c17-4570-42c8-a357-4c2eb84d1d30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- sale_id: integer (nullable = true)\n |-- product_name: string (nullable = true)\n |-- quantity: integer (nullable = true)\n |-- price: double (nullable = true)\n |-- sale_date: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Read parquet sales data\n",
    "df_parquet = spark.read.parquet(\"/data/input/*.parquet\") # '*' to read all file in the directry\n",
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64165912-0595-4695-946c-f05da8a75b89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------+------+----------+\n|sale_id|product_name|quantity| price| sale_date|\n+-------+------------+--------+------+----------+\n|      4|   Product D|      15| 49.99|2024-12-31|\n|      5|   Product E|       8| 89.99|2025-02-14|\n|      9|   Product I|      14|199.99|2025-08-30|\n|     10|   Product J|       6| 79.99|2024-04-18|\n|      1|   Product A|      10| 99.99|2024-01-15|\n|      2|   Product B|       5|149.99|2024-06-20|\n|      3|   Product C|      20| 19.99|2024-09-05|\n|      6|   Product F|      12|129.99|2025-07-22|\n|      7|   Product G|       7| 59.99|2025-03-10|\n|      8|   Product H|       9| 39.99|2024-11-11|\n+-------+------------+--------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c5ed6c-9dfb-4801-9775-789c3c230026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- sale_id: integer (nullable = true)\n |-- product_name: string (nullable = true)\n |-- quantity: integer (nullable = true)\n |-- price: double (nullable = true)\n |-- sale_date: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Read ORC sales data\n",
    "df_orc = spark.read.orc(\"/data/input/sales_data1.orc\")\n",
    "df_orc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3d9d84-9704-426a-a8f6-4f1428f0b9f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Benefits of Columnar Storage\n",
    "# Creating A Simple Python Decorator = {get time} for excecution timings\n",
    "import time\n",
    "def getTime(fxn):\n",
    "    def innerGetTime() -> str:\n",
    "        start_time = time.time()\n",
    "        fxn()\n",
    "        end_time = time.time()\n",
    "        return (f\"Execution time: {(end_time-start_time)}\")\n",
    "    print (innerGetTime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e4dbf60-2f6f-4cb2-be72-107dc1928911",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.4046027660369873\n"
     ]
    }
   ],
   "source": [
    "@getTime\n",
    "def x():\n",
    "    df = spark.read.parquet(\"/data/input/*.parquet\")\n",
    "    df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1430cbd-f575-42e7-8dba-01d222e53ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 1.2969348430633545\n"
     ]
    }
   ],
   "source": [
    "@getTime\n",
    "def x():\n",
    "    df = spark.read.parquet(\"/data/input/*.parquet\")\n",
    "    df.select(\"sale_id\").count()\n",
    "\n",
    "    # Since parquet is a COLUMNAR data format, it take less time to excute if we read only the required COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc903389-e57f-4935-a486-195a666bb0af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BONUS TIP\n",
    "RECURSIVE read using 'recuriveFileLookup'\n",
    "\n",
    "sales_recursive/\n",
    "└── sales1/1.parquet\n",
    "└── sales1/sales2/2.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c696890-259d-4e2e-9618-fd8bb8ebbaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------+-------+----------+\n|sale_id|  product_name|quantity|  price| sale_date|\n+-------+--------------+--------+-------+----------+\n|     15|Samsung Z-Fold|       5|98000.5|2025-05-15|\n+-------+--------------+--------+-------+----------+\n\n+-------+------------+--------+-------+----------+\n|sale_id|product_name|quantity|  price| sale_date|\n+-------+------------+--------+-------+----------+\n|     36|Google Pixel|      10|83000.9|2025-06-28|\n+-------+------------+--------+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"/data/input/sales_recursive/sales1/1.parquet\").show()\n",
    "spark.read.parquet(\"/data/input/sales_recursive/sales1/sales2/2.parquet\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f0b51f2-c412-49b9-bc66-09eccdc201ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- 'recursiveFileLookup' instructs Spark to look for the common folder and read the files recursively\n",
    "- It will collectively read both the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0a0db46-9567-4181-89bb-9afe642d917a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------+-------+----------+\n|sale_id|  product_name|quantity|  price| sale_date|\n+-------+--------------+--------+-------+----------+\n|     15|Samsung Z-Fold|       5|98000.5|2025-05-15|\n|     36|  Google Pixel|      10|83000.9|2025-06-28|\n+-------+--------------+--------+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.option(\"recursiveFileLookup\", True).parquet(\"/data/input/sales_recursive/\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_reading_complex_data_formats",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}